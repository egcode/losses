{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T13:00:45.951502",
     "start_time": "2017-04-23T13:00:44.296636"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import math\n",
    "import tensorlayer as tl\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "print(tf.__version__)\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "NUM_PARALLEL_CALLS = 2 # number of cpu cores\n",
    "BATCH_SIZE = 512\n",
    "REPEAT_DATASET = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T13:00:44.295728",
     "start_time": "2017-04-23T13:00:44.293871"
    },
    "collapsed": true
   },
   "source": [
    "## Dataset setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist_reader\n",
    "train_images, train_labels = mnist_reader.load_mnist('datasets/mnist', kind='train')\n",
    "test_images, test_labels = mnist_reader.load_mnist('datasets/mnist', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------\n",
      "train_images shape: (60000, 28, 28, 1)\n",
      "train_labels shape: (60000,)\n",
      "valid_images shape: (10000, 28, 28, 1)\n",
      "valid_labels shape: (10000,)\n",
      "-------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n-------------------------------\")\n",
    "print(\"train_images shape: \" + str(train_images.shape))\n",
    "print(\"train_labels shape: \" + str(train_labels.shape))\n",
    "print(\"valid_images shape: \" + str(test_images.shape))\n",
    "print(\"valid_labels shape: \" + str(test_labels.shape))\n",
    "print(\"-------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training datasets\n",
    "dx_train = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "\n",
    "# apply a one-hot transformation to each label for use in the neural network\n",
    "dy_train = tf.data.Dataset.from_tensor_slices(train_labels)\n",
    "dy_train = dy_train.map(lambda z: tf.one_hot(z, 10), num_parallel_calls=NUM_PARALLEL_CALLS)\n",
    "dy_train = dy_train.repeat()\n",
    "\n",
    "# zip the x and y training data together and shuffle, batch etc.\n",
    "train_dataset = tf.data.Dataset.zip((dx_train, dy_train)).shuffle(500)\n",
    "train_dataset = train_dataset.repeat(REPEAT_DATASET)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "# do the same for validation set\n",
    "dx_valid = tf.data.Dataset.from_tensor_slices(test_images)\n",
    "dy_valid = tf.data.Dataset.from_tensor_slices(test_labels)\n",
    "dy_valid = dy_valid.map(lambda z: tf.one_hot(z, 10), num_parallel_calls=NUM_PARALLEL_CALLS)\n",
    "dy_valid = dy_valid.repeat()\n",
    "\n",
    "test_dataset = tf.data.Dataset.zip((dx_valid, dy_valid)).shuffle(500)\n",
    "test_dataset = test_dataset.repeat(REPEAT_DATASET)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create general iterator\n",
    "# iterator = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "#                                             train_dataset.output_shapes)\n",
    "\n",
    "iterator = train_dataset.make_initializable_iterator()\n",
    "\n",
    "next_batch = iterator.get_next()\n",
    "\n",
    "# make datasets that we can initialize separately, but using the same structure via the common iterator\n",
    "training_init_op = iterator.make_initializer(train_dataset)\n",
    "test_init_op = iterator.make_initializer(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('input'):\n",
    "    input_images = tf.placeholder(tf.float32, shape=(None,28,28,1), name='input_images')\n",
    "    labels = tf.placeholder(tf.int64, shape=(None, NUM_CLASSES), name='labels')\n",
    "    \n",
    "global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "\n",
    "\n",
    "def parametric_relu(_x):\n",
    "  alphas = tf.get_variable('alpha', _x.get_shape()[-1],\n",
    "                       initializer=tf.constant_initializer(0.0),\n",
    "                        dtype=tf.float32)\n",
    "  pos = tf.nn.relu(_x)\n",
    "  neg = alphas * (_x - abs(_x)) * 0.5\n",
    "\n",
    "  return pos + neg\n",
    "\n",
    "\n",
    "# def inference(input_images):\n",
    "#     with slim.arg_scope([slim.conv2d], kernel_size=3, padding='SAME'):\n",
    "#         with slim.arg_scope([slim.max_pool2d], kernel_size=2):\n",
    "            \n",
    "#             x = slim.conv2d(input_images, num_outputs=32, scope='conv1_1')\n",
    "#             x = slim.conv2d(x, num_outputs=32, scope='conv1_2')\n",
    "#             x = slim.max_pool2d(x, scope='pool1')\n",
    "     \n",
    "#             x = slim.conv2d(x, num_outputs=64, scope='conv2_1')\n",
    "#             x = slim.conv2d(x, num_outputs=64, scope='conv2_2')\n",
    "#             x = slim.max_pool2d(x, scope='pool2')\n",
    "            \n",
    "#             x = slim.conv2d(x, num_outputs=128, scope='conv3_1')\n",
    "#             x = slim.conv2d(x, num_outputs=128, scope='conv3_2')\n",
    "#             x = slim.max_pool2d(x, scope='pool3')\n",
    "            \n",
    "#             x = slim.flatten(x, scope='flatten')\n",
    "            \n",
    "#             features3d = slim.fully_connected(x, num_outputs=3, activation_fn=None, scope='fc0')\n",
    "#             features2d = slim.fully_connected(features3d, num_outputs=2, activation_fn=None, scope='fc1')\n",
    "\n",
    "#             x = parametric_relu(features3d)\n",
    "#             x = slim.fully_connected(x, num_outputs=NUM_CLASSES, activation_fn=None, scope='fc2')\n",
    "    \n",
    "#     return x, features2d, features3d\n",
    "\n",
    "def inference(input_images):\n",
    "    with slim.arg_scope([slim.conv2d], kernel_size=3, padding='SAME'):\n",
    "        with slim.arg_scope([slim.max_pool2d], kernel_size=2):\n",
    "            \n",
    "            with tf.name_scope('conv_scope') as scope:\n",
    "                x = slim.conv2d(input_images, num_outputs=32, scope='conv1_1')\n",
    "                x = slim.conv2d(x, num_outputs=32, scope='conv1_2')\n",
    "            x = slim.max_pool2d(x, scope='pool1')\n",
    "     \n",
    "            with tf.name_scope('conv_scope') as scope:\n",
    "                x = slim.conv2d(x, num_outputs=64, scope='conv2_1')\n",
    "                x = slim.conv2d(x, num_outputs=64, scope='conv2_2')\n",
    "            x = slim.max_pool2d(x, scope='pool2')\n",
    "            \n",
    "            with tf.name_scope('conv_scope') as scope:\n",
    "                x = slim.conv2d(x, num_outputs=128, scope='conv3_1')\n",
    "                x = slim.conv2d(x, num_outputs=128, scope='conv3_2')\n",
    "            x = slim.max_pool2d(x, scope='pool3')\n",
    "            \n",
    "            x = slim.flatten(x, scope='flatten')\n",
    "            \n",
    "            features3d = slim.fully_connected(x, num_outputs=3, activation_fn=None, scope='fc0')\n",
    "#             features2d = slim.fully_connected(features3d, num_outputs=2, activation_fn=None, scope='fc1')\n",
    "\n",
    "            x = parametric_relu(features3d)\n",
    "            \n",
    "            with tf.name_scope('fc_scope') as scope:\n",
    "                x = slim.fully_connected(x, num_outputs=NUM_CLASSES, activation_fn=None, scope='fc2')\n",
    "    \n",
    "    return x, features3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arcface_loss(embedding, labels, out_num, w_init=None, s=64., m=0.5):\n",
    "    '''\n",
    "    :param embedding: the input embedding vectors\n",
    "    :param labels:  the input labels, the shape should be eg: (batch_size, 1)\n",
    "    :param s: scalar value default is 64\n",
    "    :param out_num: output class num\n",
    "    :param m: the margin value, default is 0.5\n",
    "    :return: the final cacualted output, this output is send into the tf.nn.softmax directly\n",
    "    '''\n",
    "    cos_m = math.cos(m)\n",
    "    sin_m = math.sin(m)\n",
    "    mm = sin_m * m  # issue 1\n",
    "    threshold = math.cos(math.pi - m)\n",
    "    with tf.variable_scope('arcface_loss'):\n",
    "        # inputs and weights norm\n",
    "        embedding_norm = tf.norm(embedding, axis=1, keep_dims=True)\n",
    "        embedding = tf.div(embedding, embedding_norm, name='norm_embedding')\n",
    "        weights = tf.get_variable(name='embedding_weights', shape=(embedding.get_shape().as_list()[-1], out_num),\n",
    "                                  initializer=w_init, dtype=tf.float32)\n",
    "        weights_norm = tf.norm(weights, axis=0, keep_dims=True)\n",
    "        weights = tf.div(weights, weights_norm, name='norm_weights')\n",
    "        # cos(theta+m)\n",
    "        cos_t = tf.matmul(embedding, weights, name='cos_t')\n",
    "        cos_t2 = tf.square(cos_t, name='cos_2')\n",
    "        sin_t2 = tf.subtract(1., cos_t2, name='sin_2')\n",
    "        sin_t = tf.sqrt(sin_t2, name='sin_t')\n",
    "        cos_mt = s * tf.subtract(tf.multiply(cos_t, cos_m), tf.multiply(sin_t, sin_m), name='cos_mt')\n",
    "\n",
    "        # this condition controls the theta+m should in range [0, pi]\n",
    "        #      0<=theta+m<=pi\n",
    "        #     -m<=theta<=pi-m\n",
    "        cond_v = cos_t - threshold\n",
    "        cond = tf.cast(tf.nn.relu(cond_v, name='if_else'), dtype=tf.bool)\n",
    "\n",
    "        keep_val = s*(cos_t - mm)\n",
    "        cos_mt_temp = tf.where(cond, cos_mt, keep_val)\n",
    "\n",
    "        mask = tf.one_hot(labels, depth=out_num, name='one_hot_mask')\n",
    "        # mask = tf.squeeze(mask, 1)\n",
    "        inv_mask = tf.subtract(1., mask, name='inverse_mask')\n",
    "\n",
    "        s_cos_t = tf.multiply(s, cos_t, name='scalar_cos_t')\n",
    "\n",
    "        output = tf.add(tf.multiply(s_cos_t, inv_mask), tf.multiply(cos_mt_temp, mask), name='arcface_loss_output')\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(logits, features, labels, wd_loss):\n",
    "    with tf.name_scope('loss'):\n",
    "#         with tf.name_scope('center_loss'):\n",
    "#             label_non_one_hot = tf.argmax(labels, 1)\n",
    "#             center_loss, centers, centers_update_op = get_center_loss(features, label_non_one_hot, CENTER_LOSS_ALPHA, NUM_CLASSES)        \n",
    "#         with tf.name_scope('softmax_loss'):\n",
    "#             softmax_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels, logits=logits))\n",
    "\n",
    "#         with tf.name_scope('total_loss'):\n",
    "#             softmax_loss_index = tf.cast(softmax_loss, tf.float32)\n",
    "#             total_loss = softmax_loss_index + ratio * center_loss            \n",
    "\n",
    "            \n",
    "            \n",
    "        with tf.name_scope('arcface_loss'):\n",
    "            label_non_one_hot = tf.argmax(labels, 1)\n",
    "            w_init_method = tf.contrib.layers.xavier_initializer(uniform=False)\n",
    "            \n",
    "            logit = arcface_loss(embedding=logits, labels=label_non_one_hot, w_init=w_init_method, out_num=28)\n",
    "            inference_loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logit, labels=label_non_one_hot))\n",
    "            \n",
    "            total_loss = inference_loss + wd_loss \n",
    "\n",
    "    with tf.name_scope('loss/'):\n",
    "#         tf.summary.scalar('SoftmaxLoss', softmax_loss)\n",
    "#         tf.summary.scalar('CenterLoss', center_loss)\n",
    "#         tf.summary.scalar('TotalLoss', total_loss)\n",
    "        tf.summary.scalar('ArcfaceLoss', total_loss)\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "def accuracy(labels):\n",
    "    with tf.name_scope('acc'):\n",
    "        prediction = tf.argmax(logits, 1)        \n",
    "        equality = tf.equal(prediction, tf.argmax(labels, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL]   [*] geting variables with embedding_weights\n",
      "[TL]   [*] geting variables with alpha\n",
      "[TL]   got   0: alpha:0           (3,)\n",
      "WARNING:tensorflow:From <ipython-input-7-63b1fc09e3e0>:16: calling norm (from tensorflow.python.ops.linalg_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "logits, features3d = inference(input_images)\n",
    "\n",
    "# define weight decay losses\n",
    "weight_decay = 5e-4\n",
    "wd_loss = 0\n",
    "for W in slim.get_variables(scope='conv_scope'):\n",
    "    wd_loss += tf.contrib.layers.l2_regularizer(weight_decay)(W)\n",
    "for W in slim.get_variables(scope='fc_scope'):\n",
    "    wd_loss += tf.contrib.layers.l2_regularizer(weight_decay)(W)\n",
    "for weights in tl.layers.get_variables_with_name('embedding_weights', True, True):\n",
    "    wd_loss += tf.contrib.layers.l2_regularizer(weight_decay)(weights)\n",
    "for alphas in tl.layers.get_variables_with_name('alpha', True, True):\n",
    "    wd_loss += tf.contrib.layers.l2_regularizer(weight_decay)(alphas)\n",
    "\n",
    "\n",
    "loss = loss(logits, features3d, labels, wd_loss)\n",
    "accuracy = accuracy(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = tf.argmax(logits, 1)\n",
    "init_op = tf.global_variables_initializer()\n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_data = np.mean(train_images, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 73.703, training accuracy: 13.48%\n",
      "Epoch: 0, loss: 58.820, training accuracy: 8.98%\n",
      "Epoch: 0, loss: 56.686, training accuracy: 8.98%\n",
      "Epoch: 0, loss: 56.155, training accuracy: 7.42%\n",
      "Epoch: 0, loss: 55.936, training accuracy: 9.18%\n",
      "Epoch: 0, loss: 56.083, training accuracy: 9.18%\n",
      "Epoch: 0, loss: 54.486, training accuracy: 8.40%\n",
      "Epoch: 0, loss: 54.451, training accuracy: 7.42%\n",
      "Epoch: 0, loss: 53.606, training accuracy: 9.18%\n",
      "Epoch: 0, loss: 52.977, training accuracy: 7.42%\n",
      "Epoch: 0, loss: 51.540, training accuracy: 7.23%\n",
      "Epoch: 0, loss: 51.150, training accuracy: 8.20%\n",
      "Epoch: 0, loss: 53.186, training accuracy: 11.52%\n",
      "Epoch: 0, loss: 51.276, training accuracy: 9.18%\n",
      "Epoch: 0, loss: 50.844, training accuracy: 9.18%\n",
      "Epoch: 0, loss: 49.499, training accuracy: 7.23%\n",
      "Epoch: 0, loss: 50.965, training accuracy: 7.42%\n",
      "Epoch: 0, loss: 49.925, training accuracy: 10.55%\n",
      "Epoch: 0, loss: 48.212, training accuracy: 10.35%\n",
      "Epoch: 0, loss: 47.196, training accuracy: 8.20%\n",
      "Epoch: 0, loss: 47.739, training accuracy: 12.11%\n",
      "Epoch: 0, loss: 47.298, training accuracy: 10.35%\n",
      "Epoch: 0, loss: 48.150, training accuracy: 9.57%\n",
      "Epoch: 0, loss: 47.175, training accuracy: 11.52%\n",
      "Epoch: 0, loss: 47.181, training accuracy: 10.94%\n",
      "Epoch: 0, loss: 47.073, training accuracy: 11.33%\n",
      "Epoch: 0, loss: 46.290, training accuracy: 9.18%\n",
      "Epoch: 0, loss: 45.183, training accuracy: 12.30%\n",
      "Epoch: 0, loss: 45.923, training accuracy: 11.33%\n",
      "Epoch: 0, loss: 44.906, training accuracy: 9.77%\n",
      "Epoch: 0, loss: 45.863, training accuracy: 8.98%\n",
      "Epoch: 0, loss: 46.390, training accuracy: 9.77%\n",
      "Epoch: 0, loss: 43.872, training accuracy: 11.91%\n",
      "Epoch: 0, loss: 44.057, training accuracy: 11.52%\n",
      "Epoch: 0, loss: 43.983, training accuracy: 11.52%\n",
      "Epoch: 0, loss: 43.439, training accuracy: 10.16%\n",
      "Epoch: 0, loss: 43.333, training accuracy: 9.96%\n",
      "Epoch: 0, loss: 43.463, training accuracy: 10.16%\n",
      "Epoch: 0, loss: 43.175, training accuracy: 10.74%\n",
      "Epoch: 0, loss: 42.583, training accuracy: 10.35%\n",
      "Epoch: 0, loss: 43.377, training accuracy: 10.94%\n",
      "Epoch: 0, loss: 42.728, training accuracy: 11.33%\n",
      "Epoch: 0, loss: 42.983, training accuracy: 9.57%\n",
      "Epoch: 0, loss: 41.777, training accuracy: 9.18%\n",
      "Epoch: 0, loss: 42.026, training accuracy: 8.40%\n",
      "Epoch: 0, loss: 42.599, training accuracy: 12.89%\n",
      "Epoch: 0, loss: 42.166, training accuracy: 9.77%\n",
      "Epoch: 0, loss: 41.917, training accuracy: 9.38%\n",
      "Epoch: 0, loss: 42.455, training accuracy: 9.18%\n",
      "Epoch: 0, loss: 41.299, training accuracy: 8.59%\n",
      "Epoch: 0, loss: 40.877, training accuracy: 10.55%\n",
      "Epoch: 0, loss: 41.122, training accuracy: 11.91%\n",
      "Epoch: 0, loss: 41.273, training accuracy: 10.35%\n",
      "Epoch: 0, loss: 40.715, training accuracy: 8.40%\n",
      "Epoch: 0, loss: 40.821, training accuracy: 10.16%\n",
      "Epoch: 0, loss: 40.493, training accuracy: 9.18%\n",
      "Epoch: 0, loss: 39.585, training accuracy: 8.79%\n",
      "Epoch: 0, loss: 39.401, training accuracy: 9.38%\n",
      "Epoch: 0, loss: 39.754, training accuracy: 10.94%\n",
      "Epoch: 0, loss: 40.190, training accuracy: 7.81%\n",
      "Epoch: 0, loss: 39.434, training accuracy: 8.79%\n",
      "Epoch: 0, loss: 38.669, training accuracy: 12.50%\n",
      "Epoch: 0, loss: 39.430, training accuracy: 8.98%\n",
      "Epoch: 0, loss: 39.270, training accuracy: 10.55%\n",
      "Epoch: 0, loss: 38.345, training accuracy: 9.77%\n",
      "Epoch: 0, loss: 37.864, training accuracy: 9.96%\n",
      "Epoch: 0, loss: 38.073, training accuracy: 9.77%\n",
      "Epoch: 0, loss: 38.089, training accuracy: 10.55%\n",
      "Epoch: 0, loss: 37.656, training accuracy: 9.96%\n",
      "Epoch: 0, loss: 37.771, training accuracy: 12.11%\n",
      "Epoch: 0, loss: 37.561, training accuracy: 10.16%\n",
      "Epoch: 0, loss: 37.358, training accuracy: 9.57%\n",
      "Epoch: 0, loss: 37.238, training accuracy: 13.67%\n",
      "Epoch: 0, loss: 37.054, training accuracy: 9.38%\n",
      "Epoch: 0, loss: 37.063, training accuracy: 7.81%\n",
      "Epoch: 0, loss: 37.031, training accuracy: 10.35%\n",
      "Epoch: 0, loss: 36.514, training accuracy: 9.57%\n",
      "Epoch: 0, loss: 36.986, training accuracy: 7.23%\n",
      "Epoch: 0, loss: 36.195, training accuracy: 11.52%\n",
      "Epoch: 0, loss: 35.902, training accuracy: 9.77%\n",
      "Epoch: 0, loss: 36.174, training accuracy: 9.57%\n",
      "Epoch: 0, loss: 35.641, training accuracy: 10.74%\n",
      "Epoch: 0, loss: 35.766, training accuracy: 7.62%\n",
      "Epoch: 0, loss: 35.549, training accuracy: 9.77%\n",
      "Epoch: 0, loss: 35.162, training accuracy: 12.11%\n",
      "Epoch: 0, loss: 35.242, training accuracy: 10.94%\n",
      "Epoch: 0, loss: 34.696, training accuracy: 10.55%\n",
      "Epoch: 0, loss: 35.326, training accuracy: 6.25%\n",
      "Epoch: 0, loss: 34.726, training accuracy: 11.13%\n",
      "Epoch: 0, loss: 34.609, training accuracy: 11.13%\n",
      "Epoch: 0, loss: 34.349, training accuracy: 11.72%\n",
      "Epoch: 0, loss: 34.174, training accuracy: 9.77%\n",
      "Epoch: 0, loss: 34.010, training accuracy: 10.94%\n",
      "Epoch: 0, loss: 33.797, training accuracy: 10.16%\n",
      "Epoch: 0, loss: 33.667, training accuracy: 9.38%\n",
      "Epoch: 0, loss: 33.452, training accuracy: 10.74%\n",
      "Epoch: 0, loss: 33.272, training accuracy: 9.77%\n",
      "Epoch: 0, loss: 33.399, training accuracy: 10.74%\n",
      "Epoch: 0, loss: 33.168, training accuracy: 9.77%\n",
      "Epoch: 0, loss: 33.184, training accuracy: 10.55%\n",
      "Epoch: 0, loss: 33.155, training accuracy: 10.16%\n",
      "Epoch: 0, loss: 33.122, training accuracy: 9.77%\n",
      "Epoch: 0, loss: 33.127, training accuracy: 12.11%\n",
      "Epoch: 0, loss: 33.044, training accuracy: 9.96%\n",
      "Epoch: 0, loss: 33.075, training accuracy: 11.13%\n",
      "Epoch: 0, loss: 32.940, training accuracy: 10.35%\n",
      "Epoch: 0, loss: 32.948, training accuracy: 10.94%\n",
      "Epoch: 0, loss: 32.939, training accuracy: 9.18%\n",
      "Epoch: 0, loss: 32.952, training accuracy: 11.52%\n",
      "Epoch: 0, loss: 32.890, training accuracy: 10.55%\n",
      "Epoch: 0, loss: 32.957, training accuracy: 9.18%\n",
      "Epoch: 0, loss: 32.943, training accuracy: 8.01%\n",
      "Epoch: 0, loss: 33.058, training accuracy: 11.33%\n",
      "Epoch: 0, loss: 32.798, training accuracy: 11.72%\n",
      "Epoch: 0, loss: 32.815, training accuracy: 9.77%\n",
      "Epoch: 0, loss: 32.807, training accuracy: 10.94%\n",
      "Epoch: 0, loss: 32.859, training accuracy: 8.40%\n",
      "Epoch: 0, loss: 32.840, training accuracy: 18.75%\n",
      "End of epoch 0\n",
      "Epoch: 1, loss: 32.793, training accuracy: 10.16%\n",
      "Epoch: 1, loss: 32.805, training accuracy: 8.40%\n",
      "Epoch: 1, loss: 32.676, training accuracy: 10.16%\n",
      "Epoch: 1, loss: 32.690, training accuracy: 9.96%\n",
      "Epoch: 1, loss: 32.735, training accuracy: 8.40%\n",
      "Epoch: 1, loss: 32.670, training accuracy: 10.35%\n",
      "Epoch: 1, loss: 32.714, training accuracy: 9.38%\n",
      "Epoch: 1, loss: 32.601, training accuracy: 12.11%\n",
      "Epoch: 1, loss: 32.676, training accuracy: 10.16%\n",
      "Epoch: 1, loss: 32.763, training accuracy: 9.77%\n",
      "Epoch: 1, loss: 32.543, training accuracy: 12.11%\n",
      "Epoch: 1, loss: 32.701, training accuracy: 10.94%\n",
      "Epoch: 1, loss: 32.691, training accuracy: 9.96%\n",
      "Epoch: 1, loss: 32.742, training accuracy: 9.57%\n",
      "Epoch: 1, loss: 32.627, training accuracy: 10.16%\n",
      "Epoch: 1, loss: 32.549, training accuracy: 9.96%\n",
      "Epoch: 1, loss: 32.647, training accuracy: 11.91%\n",
      "Epoch: 1, loss: 32.579, training accuracy: 10.35%\n",
      "Epoch: 1, loss: 32.628, training accuracy: 13.09%\n",
      "Epoch: 1, loss: 32.377, training accuracy: 9.38%\n",
      "Epoch: 1, loss: 32.406, training accuracy: 10.35%\n",
      "Epoch: 1, loss: 32.361, training accuracy: 10.16%\n",
      "Epoch: 1, loss: 32.551, training accuracy: 8.79%\n",
      "Epoch: 1, loss: 32.322, training accuracy: 10.94%\n",
      "Epoch: 1, loss: 32.460, training accuracy: 10.55%\n",
      "Epoch: 1, loss: 32.330, training accuracy: 13.48%\n",
      "Epoch: 1, loss: 32.352, training accuracy: 9.18%\n",
      "Epoch: 1, loss: 32.369, training accuracy: 11.13%\n",
      "Epoch: 1, loss: 32.269, training accuracy: 8.98%\n",
      "Epoch: 1, loss: 32.173, training accuracy: 11.72%\n",
      "Epoch: 1, loss: 32.095, training accuracy: 8.79%\n",
      "Epoch: 1, loss: 32.014, training accuracy: 12.50%\n",
      "Epoch: 1, loss: 31.913, training accuracy: 10.55%\n",
      "Epoch: 1, loss: 31.987, training accuracy: 13.09%\n",
      "Epoch: 1, loss: 31.748, training accuracy: 8.98%\n",
      "Epoch: 1, loss: 31.567, training accuracy: 10.74%\n",
      "Epoch: 1, loss: 31.024, training accuracy: 9.57%\n",
      "Epoch: 1, loss: 31.325, training accuracy: 10.55%\n",
      "Epoch: 1, loss: 31.602, training accuracy: 8.40%\n",
      "Epoch: 1, loss: 30.849, training accuracy: 10.55%\n",
      "Epoch: 1, loss: 30.689, training accuracy: 11.72%\n",
      "Epoch: 1, loss: 30.083, training accuracy: 10.16%\n",
      "Epoch: 1, loss: 30.453, training accuracy: 12.50%\n",
      "Epoch: 1, loss: 29.653, training accuracy: 8.59%\n",
      "Epoch: 1, loss: 29.759, training accuracy: 11.72%\n",
      "Epoch: 1, loss: 29.136, training accuracy: 8.79%\n",
      "Epoch: 1, loss: 29.464, training accuracy: 11.33%\n",
      "Epoch: 1, loss: 28.744, training accuracy: 8.79%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 28.992, training accuracy: 8.98%\n",
      "Epoch: 1, loss: 27.898, training accuracy: 9.57%\n",
      "Epoch: 1, loss: 28.168, training accuracy: 9.38%\n",
      "Epoch: 1, loss: 28.378, training accuracy: 11.72%\n",
      "Epoch: 1, loss: 29.025, training accuracy: 9.77%\n",
      "Epoch: 1, loss: 28.039, training accuracy: 8.59%\n",
      "Epoch: 1, loss: 28.336, training accuracy: 8.98%\n",
      "Epoch: 1, loss: 28.353, training accuracy: 10.74%\n",
      "Epoch: 1, loss: 28.764, training accuracy: 9.38%\n",
      "Epoch: 1, loss: 28.573, training accuracy: 10.35%\n",
      "Epoch: 1, loss: 27.771, training accuracy: 8.79%\n",
      "Epoch: 1, loss: 28.385, training accuracy: 10.55%\n",
      "Epoch: 1, loss: 28.235, training accuracy: 8.59%\n",
      "Epoch: 1, loss: 26.573, training accuracy: 9.57%\n",
      "Epoch: 1, loss: 28.482, training accuracy: 9.96%\n",
      "Epoch: 1, loss: 27.463, training accuracy: 9.38%\n",
      "Epoch: 1, loss: 27.766, training accuracy: 10.94%\n",
      "Epoch: 1, loss: 27.277, training accuracy: 9.96%\n",
      "Epoch: 1, loss: 27.011, training accuracy: 11.52%\n",
      "Epoch: 1, loss: 27.934, training accuracy: 9.57%\n",
      "Epoch: 1, loss: 27.266, training accuracy: 10.55%\n",
      "Epoch: 1, loss: 27.364, training accuracy: 11.13%\n",
      "Epoch: 1, loss: 27.639, training accuracy: 9.96%\n",
      "Epoch: 1, loss: 26.644, training accuracy: 9.96%\n",
      "Epoch: 1, loss: 27.428, training accuracy: 11.91%\n",
      "Epoch: 1, loss: 26.362, training accuracy: 10.35%\n",
      "Epoch: 1, loss: 26.150, training accuracy: 7.62%\n",
      "Epoch: 1, loss: 26.685, training accuracy: 11.33%\n",
      "Epoch: 1, loss: 27.588, training accuracy: 8.79%\n",
      "Epoch: 1, loss: 26.446, training accuracy: 8.20%\n",
      "Epoch: 1, loss: 27.131, training accuracy: 11.91%\n",
      "Epoch: 1, loss: 26.684, training accuracy: 8.79%\n",
      "Epoch: 1, loss: 26.114, training accuracy: 9.96%\n",
      "Epoch: 1, loss: 26.149, training accuracy: 9.77%\n",
      "Epoch: 1, loss: 25.944, training accuracy: 8.40%\n",
      "Epoch: 1, loss: 26.634, training accuracy: 10.16%\n",
      "Epoch: 1, loss: 25.730, training accuracy: 10.74%\n",
      "Epoch: 1, loss: 27.047, training accuracy: 9.38%\n",
      "Epoch: 1, loss: 25.636, training accuracy: 9.38%\n",
      "Epoch: 1, loss: 25.653, training accuracy: 10.16%\n",
      "Epoch: 1, loss: 27.372, training accuracy: 11.33%\n",
      "Epoch: 1, loss: 26.810, training accuracy: 12.11%\n",
      "Epoch: 1, loss: 26.276, training accuracy: 10.16%\n",
      "Epoch: 1, loss: 26.075, training accuracy: 10.74%\n",
      "Epoch: 1, loss: 26.024, training accuracy: 9.57%\n",
      "Epoch: 1, loss: 26.480, training accuracy: 9.38%\n",
      "Epoch: 1, loss: 27.159, training accuracy: 10.35%\n",
      "Epoch: 1, loss: 27.114, training accuracy: 11.52%\n",
      "Epoch: 1, loss: 26.559, training accuracy: 11.72%\n",
      "Epoch: 1, loss: 25.941, training accuracy: 8.79%\n",
      "Epoch: 1, loss: 26.472, training accuracy: 13.09%\n",
      "Epoch: 1, loss: 26.559, training accuracy: 9.18%\n",
      "Epoch: 1, loss: 24.730, training accuracy: 7.42%\n",
      "Epoch: 1, loss: 25.964, training accuracy: 10.35%\n",
      "Epoch: 1, loss: 26.606, training accuracy: 9.77%\n",
      "Epoch: 1, loss: 26.307, training accuracy: 11.13%\n",
      "Epoch: 1, loss: 26.556, training accuracy: 9.57%\n",
      "Epoch: 1, loss: 26.967, training accuracy: 11.91%\n",
      "Epoch: 1, loss: 26.536, training accuracy: 12.89%\n",
      "Epoch: 1, loss: 25.708, training accuracy: 9.96%\n",
      "Epoch: 1, loss: 26.384, training accuracy: 11.13%\n",
      "Epoch: 1, loss: 25.270, training accuracy: 9.38%\n",
      "Epoch: 1, loss: 24.746, training accuracy: 8.40%\n",
      "Epoch: 1, loss: 26.068, training accuracy: 9.38%\n",
      "Epoch: 1, loss: 25.621, training accuracy: 11.52%\n",
      "Epoch: 1, loss: 25.204, training accuracy: 9.38%\n",
      "Epoch: 1, loss: 24.811, training accuracy: 9.96%\n",
      "Epoch: 1, loss: 25.876, training accuracy: 10.74%\n",
      "Epoch: 1, loss: 25.816, training accuracy: 11.13%\n",
      "Epoch: 1, loss: 26.127, training accuracy: 9.38%\n",
      "End of epoch 1\n",
      "Epoch: 2, loss: 25.568, training accuracy: 8.59%\n",
      "Epoch: 2, loss: 26.187, training accuracy: 9.18%\n",
      "Epoch: 2, loss: 25.617, training accuracy: 9.38%\n",
      "Epoch: 2, loss: 25.091, training accuracy: 11.13%\n",
      "Epoch: 2, loss: 25.561, training accuracy: 8.59%\n",
      "Epoch: 2, loss: 26.141, training accuracy: 11.33%\n",
      "Epoch: 2, loss: 25.976, training accuracy: 9.96%\n",
      "Epoch: 2, loss: 25.909, training accuracy: 11.52%\n",
      "Epoch: 2, loss: 25.765, training accuracy: 10.16%\n",
      "Epoch: 2, loss: 25.146, training accuracy: 9.77%\n",
      "Epoch: 2, loss: 25.775, training accuracy: 11.91%\n",
      "Epoch: 2, loss: 25.952, training accuracy: 11.72%\n",
      "Epoch: 2, loss: 25.439, training accuracy: 9.77%\n",
      "Epoch: 2, loss: 26.211, training accuracy: 8.59%\n",
      "Epoch: 2, loss: 25.996, training accuracy: 10.74%\n",
      "Epoch: 2, loss: 25.370, training accuracy: 10.74%\n",
      "Epoch: 2, loss: 25.450, training accuracy: 10.16%\n",
      "Epoch: 2, loss: 26.218, training accuracy: 12.30%\n",
      "Epoch: 2, loss: 25.405, training accuracy: 9.77%\n",
      "Epoch: 2, loss: 24.999, training accuracy: 10.35%\n",
      "Epoch: 2, loss: 25.785, training accuracy: 9.96%\n",
      "Epoch: 2, loss: 24.871, training accuracy: 11.33%\n",
      "Epoch: 2, loss: 25.199, training accuracy: 8.59%\n",
      "Epoch: 2, loss: 25.914, training accuracy: 11.72%\n",
      "Epoch: 2, loss: 25.208, training accuracy: 11.52%\n",
      "Epoch: 2, loss: 25.963, training accuracy: 11.91%\n",
      "Epoch: 2, loss: 25.206, training accuracy: 9.96%\n",
      "Epoch: 2, loss: 25.760, training accuracy: 9.77%\n",
      "Epoch: 2, loss: 24.902, training accuracy: 9.96%\n",
      "Epoch: 2, loss: 24.912, training accuracy: 11.91%\n",
      "Epoch: 2, loss: 24.920, training accuracy: 10.74%\n",
      "Epoch: 2, loss: 25.760, training accuracy: 9.38%\n",
      "Epoch: 2, loss: 24.041, training accuracy: 10.55%\n",
      "Epoch: 2, loss: 24.597, training accuracy: 12.30%\n",
      "Epoch: 2, loss: 25.212, training accuracy: 10.35%\n",
      "Epoch: 2, loss: 24.710, training accuracy: 9.96%\n",
      "Epoch: 2, loss: 25.045, training accuracy: 8.98%\n",
      "Epoch: 2, loss: 24.736, training accuracy: 11.13%\n",
      "Epoch: 2, loss: 25.312, training accuracy: 9.77%\n",
      "Epoch: 2, loss: 24.420, training accuracy: 10.35%\n",
      "Epoch: 2, loss: 25.851, training accuracy: 10.94%\n",
      "Epoch: 2, loss: 24.983, training accuracy: 12.30%\n",
      "Epoch: 2, loss: 24.815, training accuracy: 9.77%\n",
      "Epoch: 2, loss: 24.755, training accuracy: 10.35%\n",
      "Epoch: 2, loss: 24.540, training accuracy: 8.01%\n",
      "Epoch: 2, loss: 24.580, training accuracy: 9.96%\n",
      "Epoch: 2, loss: 25.474, training accuracy: 10.74%\n",
      "Epoch: 2, loss: 24.585, training accuracy: 10.35%\n",
      "Epoch: 2, loss: 24.693, training accuracy: 9.57%\n",
      "Epoch: 2, loss: 24.400, training accuracy: 10.35%\n",
      "Epoch: 2, loss: 25.164, training accuracy: 9.77%\n",
      "Epoch: 2, loss: 25.785, training accuracy: 10.35%\n",
      "Epoch: 2, loss: 24.184, training accuracy: 10.74%\n",
      "Epoch: 2, loss: 24.576, training accuracy: 10.74%\n",
      "Epoch: 2, loss: 23.100, training accuracy: 8.59%\n",
      "Epoch: 2, loss: 23.911, training accuracy: 8.20%\n",
      "Epoch: 2, loss: 24.435, training accuracy: 9.77%\n",
      "Epoch: 2, loss: 24.432, training accuracy: 8.98%\n",
      "Epoch: 2, loss: 23.726, training accuracy: 10.55%\n",
      "Epoch: 2, loss: 23.066, training accuracy: 9.38%\n",
      "Epoch: 2, loss: 23.120, training accuracy: 8.98%\n",
      "Epoch: 2, loss: 24.025, training accuracy: 9.18%\n",
      "Epoch: 2, loss: 23.803, training accuracy: 9.57%\n",
      "Epoch: 2, loss: 23.801, training accuracy: 10.16%\n",
      "Epoch: 2, loss: 22.307, training accuracy: 10.35%\n",
      "Epoch: 2, loss: 22.061, training accuracy: 9.38%\n",
      "Epoch: 2, loss: 23.109, training accuracy: 11.72%\n",
      "Epoch: 2, loss: 22.847, training accuracy: 11.13%\n",
      "Epoch: 2, loss: 22.071, training accuracy: 9.57%\n",
      "Epoch: 2, loss: 23.704, training accuracy: 13.67%\n",
      "Epoch: 2, loss: 21.786, training accuracy: 9.57%\n",
      "Epoch: 2, loss: 22.515, training accuracy: 9.38%\n",
      "Epoch: 2, loss: 23.487, training accuracy: 10.16%\n",
      "Epoch: 2, loss: 22.388, training accuracy: 11.72%\n",
      "Epoch: 2, loss: 22.639, training accuracy: 6.25%\n",
      "Epoch: 2, loss: 21.042, training accuracy: 9.38%\n",
      "Epoch: 2, loss: 22.011, training accuracy: 8.98%\n",
      "Epoch: 2, loss: 21.017, training accuracy: 9.18%\n",
      "Epoch: 2, loss: 21.683, training accuracy: 11.33%\n",
      "Epoch: 2, loss: 22.606, training accuracy: 8.79%\n",
      "Epoch: 2, loss: 21.477, training accuracy: 10.35%\n",
      "Epoch: 2, loss: 22.357, training accuracy: 8.79%\n",
      "Epoch: 2, loss: 21.137, training accuracy: 9.96%\n",
      "Epoch: 2, loss: 21.768, training accuracy: 8.98%\n",
      "Epoch: 2, loss: 22.114, training accuracy: 13.67%\n",
      "Epoch: 2, loss: 22.243, training accuracy: 8.98%\n",
      "Epoch: 2, loss: 19.845, training accuracy: 10.55%\n",
      "Epoch: 2, loss: 22.388, training accuracy: 9.77%\n",
      "Epoch: 2, loss: 21.994, training accuracy: 11.72%\n",
      "Epoch: 2, loss: 21.153, training accuracy: 9.96%\n",
      "Epoch: 2, loss: 21.642, training accuracy: 11.33%\n",
      "Epoch: 2, loss: 22.450, training accuracy: 8.01%\n",
      "Epoch: 2, loss: 21.860, training accuracy: 11.13%\n",
      "Epoch: 2, loss: 21.308, training accuracy: 9.57%\n",
      "Epoch: 2, loss: 21.462, training accuracy: 9.38%\n",
      "Epoch: 2, loss: 21.650, training accuracy: 12.89%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 21.305, training accuracy: 10.35%\n",
      "Epoch: 2, loss: 21.579, training accuracy: 12.30%\n",
      "Epoch: 2, loss: 21.452, training accuracy: 8.59%\n",
      "Epoch: 2, loss: 21.695, training accuracy: 10.55%\n",
      "Epoch: 2, loss: 21.540, training accuracy: 8.79%\n",
      "Epoch: 2, loss: 20.953, training accuracy: 11.33%\n",
      "Epoch: 2, loss: 21.572, training accuracy: 9.77%\n",
      "Epoch: 2, loss: 20.101, training accuracy: 8.59%\n",
      "Epoch: 2, loss: 21.348, training accuracy: 9.77%\n",
      "Epoch: 2, loss: 20.954, training accuracy: 10.55%\n",
      "Epoch: 2, loss: 20.821, training accuracy: 12.30%\n",
      "Epoch: 2, loss: 20.622, training accuracy: 10.35%\n",
      "Epoch: 2, loss: 20.711, training accuracy: 9.96%\n",
      "Epoch: 2, loss: 21.031, training accuracy: 13.09%\n",
      "Epoch: 2, loss: 19.437, training accuracy: 7.23%\n",
      "Epoch: 2, loss: 19.992, training accuracy: 10.74%\n",
      "Epoch: 2, loss: 21.248, training accuracy: 10.94%\n",
      "Epoch: 2, loss: 20.089, training accuracy: 12.30%\n",
      "Epoch: 2, loss: 19.963, training accuracy: 9.96%\n",
      "Epoch: 2, loss: 19.348, training accuracy: 8.98%\n",
      "Epoch: 2, loss: 21.903, training accuracy: 10.55%\n",
      "Epoch: 2, loss: 17.249, training accuracy: 9.38%\n",
      "End of epoch 2\n",
      "Epoch: 3, loss: 19.896, training accuracy: 9.57%\n",
      "Epoch: 3, loss: 19.115, training accuracy: 8.79%\n",
      "Epoch: 3, loss: 20.628, training accuracy: 10.74%\n",
      "Epoch: 3, loss: 19.679, training accuracy: 10.74%\n",
      "Epoch: 3, loss: 19.917, training accuracy: 7.62%\n",
      "Epoch: 3, loss: 20.411, training accuracy: 10.35%\n",
      "Epoch: 3, loss: 19.481, training accuracy: 10.35%\n",
      "Epoch: 3, loss: 19.592, training accuracy: 10.16%\n",
      "Epoch: 3, loss: 18.807, training accuracy: 10.55%\n",
      "Epoch: 3, loss: 18.297, training accuracy: 11.72%\n",
      "Epoch: 3, loss: 18.582, training accuracy: 8.79%\n",
      "Epoch: 3, loss: 18.553, training accuracy: 12.89%\n",
      "Epoch: 3, loss: 19.897, training accuracy: 8.40%\n",
      "Epoch: 3, loss: 18.904, training accuracy: 12.50%\n",
      "Epoch: 3, loss: 18.480, training accuracy: 10.16%\n",
      "Epoch: 3, loss: 17.241, training accuracy: 10.35%\n",
      "Epoch: 3, loss: 19.963, training accuracy: 11.13%\n",
      "Epoch: 3, loss: 18.799, training accuracy: 10.35%\n",
      "Epoch: 3, loss: 17.629, training accuracy: 10.35%\n",
      "Epoch: 3, loss: 18.095, training accuracy: 11.33%\n",
      "Epoch: 3, loss: 17.904, training accuracy: 10.35%\n",
      "Epoch: 3, loss: 17.273, training accuracy: 9.96%\n",
      "Epoch: 3, loss: 17.109, training accuracy: 10.16%\n",
      "Epoch: 3, loss: 16.432, training accuracy: 9.38%\n",
      "Epoch: 3, loss: 16.739, training accuracy: 11.72%\n",
      "Epoch: 3, loss: 17.361, training accuracy: 10.55%\n",
      "Epoch: 3, loss: 16.249, training accuracy: 12.89%\n",
      "Epoch: 3, loss: 17.189, training accuracy: 11.52%\n",
      "Epoch: 3, loss: 17.138, training accuracy: 11.52%\n",
      "Epoch: 3, loss: 16.771, training accuracy: 9.18%\n",
      "Epoch: 3, loss: 15.127, training accuracy: 10.74%\n",
      "Epoch: 3, loss: 15.768, training accuracy: 9.96%\n",
      "Epoch: 3, loss: 15.527, training accuracy: 11.33%\n",
      "Epoch: 3, loss: 15.929, training accuracy: 12.11%\n",
      "Epoch: 3, loss: 14.715, training accuracy: 10.74%\n",
      "Epoch: 3, loss: 15.765, training accuracy: 11.52%\n",
      "Epoch: 3, loss: 15.028, training accuracy: 9.57%\n",
      "Epoch: 3, loss: 13.377, training accuracy: 8.79%\n",
      "Epoch: 3, loss: 14.278, training accuracy: 9.96%\n",
      "Epoch: 3, loss: 13.279, training accuracy: 11.72%\n",
      "Epoch: 3, loss: 14.046, training accuracy: 9.57%\n",
      "Epoch: 3, loss: 14.299, training accuracy: 10.16%\n",
      "Epoch: 3, loss: 15.137, training accuracy: 12.70%\n",
      "Epoch: 3, loss: 13.570, training accuracy: 8.40%\n",
      "Epoch: 3, loss: 13.540, training accuracy: 10.55%\n",
      "Epoch: 3, loss: 12.293, training accuracy: 10.55%\n",
      "Epoch: 3, loss: 13.470, training accuracy: 10.35%\n",
      "Epoch: 3, loss: 12.953, training accuracy: 10.74%\n",
      "Epoch: 3, loss: 12.360, training accuracy: 8.98%\n",
      "Epoch: 3, loss: 11.792, training accuracy: 11.72%\n",
      "Epoch: 3, loss: 12.171, training accuracy: 9.38%\n",
      "Epoch: 3, loss: 11.657, training accuracy: 9.77%\n",
      "Epoch: 3, loss: 12.890, training accuracy: 11.13%\n",
      "Epoch: 3, loss: 11.054, training accuracy: 10.16%\n",
      "Epoch: 3, loss: 11.734, training accuracy: 8.59%\n",
      "Epoch: 3, loss: 10.565, training accuracy: 10.74%\n",
      "Epoch: 3, loss: 11.978, training accuracy: 8.59%\n",
      "Epoch: 3, loss: 12.016, training accuracy: 9.77%\n",
      "Epoch: 3, loss: 10.095, training accuracy: 8.98%\n",
      "Epoch: 3, loss: 11.820, training accuracy: 9.38%\n",
      "Epoch: 3, loss: 10.586, training accuracy: 11.33%\n",
      "Epoch: 3, loss: 12.114, training accuracy: 9.77%\n",
      "Epoch: 3, loss: 11.497, training accuracy: 9.18%\n",
      "Epoch: 3, loss: 10.774, training accuracy: 12.11%\n",
      "Epoch: 3, loss: 10.958, training accuracy: 10.35%\n",
      "Epoch: 3, loss: 9.527, training accuracy: 10.74%\n",
      "Epoch: 3, loss: 9.772, training accuracy: 9.96%\n",
      "Epoch: 3, loss: 10.646, training accuracy: 10.55%\n",
      "Epoch: 3, loss: 11.295, training accuracy: 9.96%\n",
      "Epoch: 3, loss: 9.702, training accuracy: 11.33%\n",
      "Epoch: 3, loss: 9.324, training accuracy: 9.96%\n",
      "Epoch: 3, loss: 10.605, training accuracy: 9.96%\n",
      "Epoch: 3, loss: 10.182, training accuracy: 13.48%\n",
      "Epoch: 3, loss: 10.633, training accuracy: 9.18%\n",
      "Epoch: 3, loss: 10.150, training accuracy: 9.77%\n",
      "Epoch: 3, loss: 9.877, training accuracy: 10.16%\n",
      "Epoch: 3, loss: 11.661, training accuracy: 8.01%\n",
      "Epoch: 3, loss: 10.353, training accuracy: 8.01%\n",
      "Epoch: 3, loss: 9.666, training accuracy: 10.35%\n",
      "Epoch: 3, loss: 10.509, training accuracy: 9.77%\n",
      "Epoch: 3, loss: 9.772, training accuracy: 9.77%\n",
      "Epoch: 3, loss: 9.784, training accuracy: 8.59%\n",
      "Epoch: 3, loss: 9.638, training accuracy: 9.38%\n",
      "Epoch: 3, loss: 9.444, training accuracy: 11.91%\n",
      "Epoch: 3, loss: 10.387, training accuracy: 10.35%\n",
      "Epoch: 3, loss: 9.709, training accuracy: 9.18%\n",
      "Epoch: 3, loss: 9.800, training accuracy: 10.16%\n",
      "Epoch: 3, loss: 10.190, training accuracy: 8.59%\n",
      "Epoch: 3, loss: 8.939, training accuracy: 9.96%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5deade84c61a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mimg_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             l, _, acc, summary_str = sess.run([loss, optimizer, accuracy, summary_op],\n\u001b[0;32m---> 22\u001b[0;31m                                                  feed_dict={input_images: img_batch-mean_data,labels: label_batch})\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "# run the training\n",
    "epochs = 4000\n",
    "sess = tf.Session()\n",
    "# sess = tf_debug.TensorBoardDebugWrapperSession(sess, \"Eugenes-MBP:7000\")\n",
    "# Start Tensorflow from this file 'tensorboard --logdir=/tmp/mnist_log --debugger_port 7000'\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(init_op)\n",
    "sess.run(training_init_op)\n",
    "\n",
    "writer = tf.summary.FileWriter('/tmp/mnist_log', sess.graph)\n",
    "# Start Tensorflow from this file 'tensorboard --logdir=/tmp/mnist_log'\n",
    "\n",
    "for i in range(epochs):\n",
    "    sess.run(iterator.initializer)\n",
    "    while True:\n",
    "        try:\n",
    "            img_batch, label_batch = sess.run(next_batch)\n",
    "            l, _, acc, summary_str = sess.run([loss, optimizer, accuracy, summary_op],\n",
    "                                                 feed_dict={input_images: img_batch-mean_data,labels: label_batch})\n",
    "\n",
    "            writer.add_summary(summary_str, global_step=epochs)\n",
    "\n",
    "#             if i % 50 == 0:\n",
    "            print(\"Epoch: {}, loss: {:.3f}, training accuracy: {:.2f}%\".format(i, l, acc * 100)) \n",
    "\n",
    "        except tf.errors.OutOfRangeError:\n",
    "#             if i % 50 == 0:\n",
    "            print(\"End of epoch %d\" % i)\n",
    "            break\n",
    "\n",
    "\n",
    "# now setup the validation run\n",
    "# test_iters = 100\n",
    "# # re-initialize the iterator, but this time with validation data\n",
    "# sess.run(test_init_op)\n",
    "# avg_acc = 0\n",
    "# for i in range(test_iters):\n",
    "#     img_batch, label_batch = sess.run(next_batch)\n",
    "#     acc = sess.run([accuracy], feed_dict={input_images: img_batch-mean_data,labels: label_batch})\n",
    "#     avg_acc += acc[0]\n",
    "# print(\"Average validation set accuracy over {} iterations is {:.2f}%\".format(test_iters, (avg_acc / test_iters) * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat = sess.run(features2d, feed_dict={input_images:train_images[:20000]-mean_data})\n",
    "\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# labels = train_labels[:20000]\n",
    "\n",
    "# f = plt.figure(figsize=(16,9))\n",
    "# c = ['#ff0000', '#ffff00', '#00ff00', '#00ffff', '#0000ff', \n",
    "#      '#ff00ff', '#990000', '#999900', '#009900', '#009999']\n",
    "# for i in range(10):\n",
    "#     plt.plot(feat[labels==i,0].flatten(), feat[labels==i,1].flatten(), '.', c=c[i])\n",
    "# plt.legend(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-04-23T13:02:30.484009",
     "start_time": "2017-04-23T13:02:29.879168"
    }
   },
   "outputs": [],
   "source": [
    "# feat = sess.run(features2d, feed_dict={input_images:test_images[:20000]-mean_data})\n",
    "\n",
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# labels = test_labels[:20000]\n",
    "\n",
    "# f = plt.figure(figsize=(16,9))\n",
    "# c = ['#ff0000', '#ffff00', '#00ff00', '#00ffff', '#0000ff', \n",
    "#      '#ff00ff', '#990000', '#999900', '#009900', '#009999']\n",
    "# for i in range(10):\n",
    "#     plt.plot(feat[labels==i,0].flatten(), feat[labels==i,1].flatten(), '.', c=c[i])\n",
    "# plt.legend(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize train_data 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "feat = sess.run(features3d, feed_dict={input_images:train_images[:10000]-mean_data})\n",
    "labels = train_labels[:10000]\n",
    "\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "for i in range(10):\n",
    "    # Data for three-dimensional scattered points\n",
    "    xdata = feat[labels==i,2].flatten()\n",
    "    ydata = feat[labels==i,0].flatten()\n",
    "    zdata = feat[labels==i,1].flatten()\n",
    "    ax.scatter3D(xdata, ydata, zdata);\n",
    "ax.legend(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize test_data 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "feat = sess.run(features3d, feed_dict={input_images:test_images[:10000]-mean_data})\n",
    "labels = test_labels[:10000]\n",
    "\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "ax = plt.axes(projection='3d')\n",
    "\n",
    "for i in range(10):\n",
    "    # Data for three-dimensional scattered points\n",
    "    xdata = feat[labels==i,2].flatten()\n",
    "    ydata = feat[labels==i,0].flatten()\n",
    "    zdata = feat[labels==i,1].flatten()\n",
    "    ax.scatter3D(xdata, ydata, zdata);\n",
    "ax.legend(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'],loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 11\n",
    "digit = test_images[ind].reshape(28,28)\n",
    "plt.title('this is  --->   ' + str(test_labels[ind]))\n",
    "plt.imshow(digit, cmap='gray')\n",
    "\n",
    "tf.reset_default_graph()\n",
    "feed_image = test_images[ind].reshape(1,28,28,1)\n",
    "prediction = sess.run([logits],feed_dict={input_images: feed_image})\n",
    "print(\"prediction: \" + str(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
